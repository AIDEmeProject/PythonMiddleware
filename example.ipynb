{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add path to explore_by_example src folder\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "# import usual libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# our system imports\n",
    "from aideme import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fscore(metrics):\n",
    "    df_list = [pd.DataFrame.from_dict({i: metric for i, metric in enumerate(ls)}, orient='index') for ls in metrics]\n",
    "    avg = sum([df['fscore'][~df['fscore'].isna()] for df in df_list]) / len(df_list)\n",
    "    avg.plot(ylim=[0,1], marker='o')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DUMMY DATA\n",
    "N = int(1e5)\n",
    "dim = 2\n",
    "limit = 2 * (0.001)**(1. / dim)\n",
    "rng = np.random.RandomState(0)\n",
    "X = rng.uniform(low=-2, high=2, size=(N, dim))  # do not forget to standardize the data. For this distribution, it should be fine without it.\n",
    "y_subspace = np.vstack([np.abs(X[:, i]) < limit for i in range(dim)]).T.astype('float')  # partial labels (for each subspace)\n",
    "y = y_subspace.min(axis=1)\n",
    "labeled_set = LabeledSet(y, partial=y_subspace)\n",
    "\n",
    "# visualize data distribution\n",
    "print('selectivity :', 100 * y.sum() / len(y), '%')\n",
    "\n",
    "#plt.figure(figsize=(10,8))\n",
    "#plt.scatter(X[:, 0], X[:, 1], s=0.5, c=['b' if lb else 'r' for lb in y])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NO FACTORIZATION EXAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET-UP EXPLORATION CONFIGURATION\n",
    "NUMBER_OF_ITERATIONS = 100  # number of points to be labeled by the user\n",
    "SUBSAMPLING = None\n",
    "INITIAL_SAMPLER = stratified_sampler(labeled_set, pos=1, neg=1)  # start with one random positive sample and one random negative sample\n",
    "#INITIAL_SAMPLER = random_sampler(10)\n",
    "CALLBACK = [ # callback functions to be called at the end of each iteration\n",
    "    classification_metrics(y, 'fscore'), \n",
    "    three_set_metric,\n",
    "]\n",
    "CALLBACK_SKIP = 10\n",
    "PRINT_CALLBACK_RESULT = True\n",
    "CONVERGENCE_CRITERIA = [\n",
    "    max_iter_reached(NUMBER_OF_ITERATIONS),\n",
    "    #all_points_are_known,\n",
    "    #metric_reached_threshold('fscore', 0.8),\n",
    "    #metric_reached_threshold('tsm', 0.9),\n",
    "]\n",
    "\n",
    "explore = PoolBasedExploration(INITIAL_SAMPLER, SUBSAMPLING, CALLBACK, CALLBACK_SKIP, PRINT_CALLBACK_RESULT, CONVERGENCE_CRITERIA)\n",
    "\n",
    "# CHOOSE AN ALGORITHM\n",
    "#learner = RandomSampler(SVC(C=1e5, kernel='rbf', gamma='auto'))  # choose a random point\n",
    "learner = SimpleMargin(C=1024, kernel='rbf')  # choose point closest to SVM decision boundary\n",
    "#learner = KernelQueryByCommittee(kernel='rbf', sampling='deterministic', n_samples=8, warmup=1000, thin=100, rounding=True)  # version space algorithm\n",
    "learner = DualSpaceModel(learner, sample_unknown_proba=0.5, mode='positive')  # Dual Space model\n",
    "\n",
    "\n",
    "# RUN EXPLORATION\n",
    "metrics = explore.run(X, labeled_set, learner, repeat=1)  # 'repeat' specifies how many times to repeat the exploration process\n",
    "\n",
    "# COMPUTE AVERAGE F-SCORE OVER ALL REPEATS AND PLOT\n",
    "#plot_fscore(metrics)\n",
    "df = pd.DataFrame.from_dict({i: metric for i, metric in enumerate(metrics[0])}, orient='index')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACTORIZATION EXAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET-UP EXPLORATION CONFIGURATION\n",
    "NUMBER_OF_ITERATIONS = 100  # number of points to be labeled by the user\n",
    "SUBSAMPLING = None\n",
    "INITIAL_SAMPLER = stratified_sampler(labeled_set, pos=1, neg=1)  # start with one random positive sample and one random negative sample\n",
    "#INITIAL_SAMPLER = random_sampler(10)\n",
    "CALLBACK = [ # callback functions to be called at the end of each iteration\n",
    "    classification_metrics(y, 'fscore'), \n",
    "    three_set_metric,\n",
    "]\n",
    "CALLBACK_SKIP = 10\n",
    "PRINT_CALLBACK_RESULT = True\n",
    "CONVERGENCE_CRITERIA = [\n",
    "    max_iter_reached(NUMBER_OF_ITERATIONS),\n",
    "    #all_points_are_known,\n",
    "    #metric_reached_threshold('fscore', 0.8),\n",
    "    metric_reached_threshold('tsm', 0.9),\n",
    "]\n",
    "\n",
    "explore = PoolBasedExploration(INITIAL_SAMPLER, SUBSAMPLING, CALLBACK, CALLBACK_SKIP, PRINT_CALLBACK_RESULT, CONVERGENCE_CRITERIA)\n",
    "\n",
    "# Factorized AL algorithms\n",
    "PARTITION = [[i] for i in range(dim)]  #[[0], [1]]\n",
    "\n",
    "# FACTORIZED VERSION SPACE\n",
    "# label_function = 'AND', 'OR', 'PROD'\n",
    "# loss = 'GREEDY', 'SQUARED', 'PRODUCT'\n",
    "#learner = SubspatialVersionSpace(warmup=100, thin=10, n_samples=8, rounding=True, kernel='rbf', gamma=None, partition=PARTITION, label_function='AND', loss='GREEDY')\n",
    "\n",
    "# FACTORIZED SIMPLE MARGIN\n",
    "#learner = SubspatialSimpleMargin(C=1024, kernel='rbf', gamma=5, partition=PARTITION, label_function='AND')\n",
    "\n",
    "# FACTORIZED DSM\n",
    "learner = DualSpaceModel(SimpleMargin(C=1024, kernel='rbf'), mode='positive', sample_unknown_proba=0.5, partition=PARTITION)  # Dual Space model\n",
    "\n",
    "\n",
    "# RUN EXPLORATION\n",
    "metrics = explore.run(X, labeled_set, learner, repeat=1)  # use y_subspace here\n",
    "\n",
    "# COMPUTE AVERAGE F-SCORE OVER ALL REPEATS AND PLOT\n",
    "#plot_fscore(metrics)\n",
    "df = pd.DataFrame.from_dict({i: metric for i, metric in enumerate(metrics[0])}, orient='index')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
