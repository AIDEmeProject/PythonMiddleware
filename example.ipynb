{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import usual libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# our system imports\n",
    "from aideme import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fscore(metrics):\n",
    "    df_list = [pd.DataFrame.from_dict({i: metric for i, metric in enumerate(ls)}, orient='index') for ls in metrics]\n",
    "    avg = sum([df['fscore'][~df['fscore'].isna()] for df in df_list]) / len(df_list)\n",
    "    avg.plot(ylim=[0,1], marker='o')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selectivity : 0.093 %\n"
     ]
    }
   ],
   "source": [
    "# DUMMY DATA\n",
    "N = int(2e5)\n",
    "dim = 2\n",
    "PARTITION = [[0], [1]]#[[0, 1], [2, 3], [4], [5]]\n",
    "limit = 0.06 #0.63\n",
    "rng = np.random.RandomState(0)\n",
    "X = rng.uniform(low=-2, high=2, size=(N, dim))  # do not forget to standardize the data. For this distribution, it should be fine without it.\n",
    "y_subspace = np.vstack([np.all(np.abs(X[:, p]) < limit, axis=1) for p in PARTITION]).T.astype('float')  # partial labels (for each subspace)\n",
    "y = y_subspace.min(axis=1)\n",
    "\n",
    "labeled_set = LabeledSet(y, y_subspace)\n",
    "\n",
    "# visualize data distribution\n",
    "print('selectivity :', 100 * y.sum() / len(y), '%')\n",
    "\n",
    "#plt.figure(figsize=(10,8))\n",
    "#plt.scatter(X[:, 0], X[:, 1], s=0.05, c=['b' if lb else 'r' for lb in y])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1 , fscore: 0.00262786097767731 iter_time: 0.03423679700000193\n",
      "iter: 6 , fscore: 0.01840855106888361 iter_time: 0.06291854200000557\n",
      "iter: 11 , fscore: 0.05808869456589631 iter_time: 0.08314439999999479\n",
      "iter: 16 , fscore: 0.07261853908586074 iter_time: 0.10810439400000149\n",
      "iter: 21 , fscore: 0.2884012539184953 iter_time: 0.13141552899999454\n",
      "iter: 26 , fscore: 0.42448979591836733 iter_time: 0.15689795000000117\n",
      "iter: 31 , fscore: 0.8054298642533937 iter_time: 0.19642608899999914\n",
      "iter: 36 , fscore: 0.9043927648578811 iter_time: 0.21955241700000272\n",
      "iter: 41 , fscore: 0.9067357512953368 iter_time: 0.2522048689999963\n",
      "iter: 46 , fscore: 0.9114583333333334 iter_time: 0.28106112399999716\n",
      "iter: 51 , fscore: 0.9114583333333334 iter_time: 0.30975556300000306\n"
     ]
    }
   ],
   "source": [
    "# SET-UP EXPLORATION CONFIGURATION\n",
    "REPEAT = 1\n",
    "NUMBER_OF_ITERATIONS = 50  # number of points to be labeled by the user\n",
    "\n",
    "SUBSAMPLING = None \n",
    "\n",
    "INITIAL_SAMPLER = stratified_sampler(labeled_set, pos=1, neg=1)  # start with one random positive sample and one random negative sample\n",
    "#INITIAL_SAMPLER = random_sampler(10)\n",
    "\n",
    "CALLBACK = [ # callback functions to be called at the end of each iteration\n",
    "    classification_metrics(X, labeled_set.labels, ['fscore']), \n",
    "    #three_set_metric,\n",
    "]\n",
    "CALLBACK_SKIP = 5\n",
    "\n",
    "\n",
    "CONVERGENCE_CRITERIA = [\n",
    "    max_iter_reached(NUMBER_OF_ITERATIONS),\n",
    "    #all_points_are_known,\n",
    "    #metric_reached_threshold('fscore', 0.8),\n",
    "    #metric_reached_threshold('tsm', 0.9),\n",
    "]\n",
    "\n",
    "#NOISE_INJECTOR = random_noise_injector(0)  # None, random_noise_injector, gaussian_noise_injector\n",
    "\n",
    "SEED = [0]\n",
    "\n",
    "explore = PoolBasedExploration(INITIAL_SAMPLER, SUBSAMPLING, CALLBACK, CALLBACK_SKIP, CONVERGENCE_CRITERIA)\n",
    "\n",
    "# ACTIVE LEARNING ALGORITHMS\n",
    "#learner = RandomSampler(SVC(C=1e5, kernel='rbf', gamma='auto'))  # choose a random point\n",
    "#learner = SimpleMargin(C=1e7, kernel='rbf')  # choose point closest to SVM decision boundary\n",
    "#learner = DualSpaceModel(learner, sample_unknown_proba=0.5, mode='positive')  # Dual Space model\n",
    "#learner = KernelVersionSpace(n_samples=16, warmup=100, thin=100, strategy='opt', rounding_cache=True)  # version space algorithm\n",
    "#learner = BayesianKernelVersionSpace(n_samples=16, warmup=100, thin=100, sampler='stan', prior='improper', prior_std=100)  # version space algorithm\n",
    "learner = BayesianKernelVersionSpace(sampler='approximate', prior='improper', n_samples=100, prior_std=1000)  # version space algorithm\n",
    "\n",
    "# FACTORIZED ALGORITHMS\n",
    "#PARTITION = [[0], [1]]\n",
    "#learner = FactorizedDualSpaceModel(SimpleMargin(C=1024, kernel='rbf'), partition=PARTITION, mode='positive', sample_unknown_proba=0.5)  # Dual Space model\n",
    "#learner = SubspatialVersionSpace(n_samples=8, warmup=100, thin=100, rounding=True, rounding_cache=True, z_cut=True, use_cython=True, strategy='opt', partition=PARTITION, label_function='AND', loss='GREEDY')\n",
    "#learner = SubspatialSimpleMargin(C=1024, kernel='rbf', gamma=5, partition=PARTITION, label_function='AND')\n",
    "\n",
    "\n",
    "# RUN EXPLORATION\n",
    "#metrics = explore.run(X, labeled_set, learner, repeat=REPEAT, seeds=SEED)  # 'repeat' specifies how many times to repeat the exploration process\n",
    "dfs = []\n",
    "\n",
    "#import logging\n",
    "#logging.getLogger('pystan').setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "for run in explore.run(X, labeled_set, learner, repeat=REPEAT, seeds=SEED, return_generator=True):\n",
    "    for i, m in enumerate(run): \n",
    "        if 'fscore' in m:\n",
    "            print('iter:', i, ', fscore:', m['fscore'], 'iter_time:', m['iter_time'])    \n",
    "\n",
    "# COMPUTE AVERAGE F-SCORE OVER ALL REPEATS AND PLOT\n",
    "#dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
