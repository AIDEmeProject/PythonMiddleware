{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import usual libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# our system imports\n",
    "from aideme import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fscore(metrics):\n",
    "    df_list = [pd.DataFrame.from_dict({i: metric for i, metric in enumerate(ls)}, orient='index') for ls in metrics]\n",
    "    avg = sum([df['fscore'][~df['fscore'].isna()] for df in df_list]) / len(df_list)\n",
    "    avg.plot(ylim=[0,1], marker='o')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DUMMY DATA\n",
    "N = int(1e6)\n",
    "dim = 2\n",
    "limit = 2 * (0.001)**(1. / dim)\n",
    "rng = np.random.RandomState(0)\n",
    "X = rng.uniform(low=-2, high=2, size=(N, dim))  # do not forget to standardize the data. For this distribution, it should be fine without it.\n",
    "y_subspace = np.vstack([np.abs(X[:, i]) < limit for i in range(dim)]).T.astype('float')  # partial labels (for each subspace)\n",
    "y = y_subspace.min(axis=1)\n",
    "\n",
    "index = -10 * np.arange(len(X))\n",
    "labeled_set = LabeledSet(y, y_subspace, index)\n",
    "\n",
    "# visualize data distribution\n",
    "print('selectivity :', 100 * y.sum() / len(y), '%')\n",
    "\n",
    "#plt.figure(figsize=(10,8))\n",
    "#plt.scatter(X[:, 0], X[:, 1], s=0.5, c=['b' if lb else 'r' for lb in y])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single experiment example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET-UP EXPLORATION CONFIGURATION\n",
    "REPEAT = 1\n",
    "NUMBER_OF_ITERATIONS = 100  # number of points to be labeled by the user\n",
    "\n",
    "SUBSAMPLING = 50000\n",
    "\n",
    "INITIAL_SAMPLER = stratified_sampler(labeled_set, pos=1, neg=1)  # start with one random positive sample and one random negative sample\n",
    "#INITIAL_SAMPLER = random_sampler(10)\n",
    "\n",
    "CALLBACK = [ # callback functions to be called at the end of each iteration\n",
    "    classification_metrics(labeled_set.labels, ['fscore']), \n",
    "    three_set_metric,\n",
    "]\n",
    "CALLBACK_SKIP = 4\n",
    "PRINT_CALLBACK_RESULT = True\n",
    "\n",
    "CONVERGENCE_CRITERIA = [\n",
    "    max_iter_reached(NUMBER_OF_ITERATIONS),\n",
    "    #all_points_are_known,\n",
    "    #metric_reached_threshold('fscore', 0.8),\n",
    "    #metric_reached_threshold('tsm', 0.9),\n",
    "]\n",
    "\n",
    "SEED = list(range(REPEAT))\n",
    "\n",
    "explore = PoolBasedExploration(INITIAL_SAMPLER, SUBSAMPLING, CALLBACK, CALLBACK_SKIP, PRINT_CALLBACK_RESULT, CONVERGENCE_CRITERIA)\n",
    "\n",
    "# Non-Factorized AL\n",
    "#learner = RandomSampler(SVC(C=1e5, kernel='rbf', gamma='auto'))  # choose a random point\n",
    "#learner = SimpleMargin(C=1024, kernel='rbf')  # choose point closest to SVM decision boundary\n",
    "#learner = DualSpaceModel(learner, sample_unknown_proba=0.5, mode='positive')  # Dual Space model\n",
    "\n",
    "learner = KernelQueryByCommittee(strategy='opt', rounding_cache=True, z_cut=True, jitter=1e-12, warmup=100, thin=100, n_samples=16)  # version space algorithm\n",
    "#learner = KernelQueryByCommittee(sampling='deterministic', strategy='opt', z_cut=False)  # version space algorithm\n",
    "#learner = KernelQueryByCommittee(sampling='deterministic', strategy='opt', z_cut=True)  # version space algorithm\n",
    "\n",
    "\n",
    "# Factorized AL algorithms\n",
    "PARTITION = [[i] for i in range(dim)]  #[[0], [1]]\n",
    "\n",
    "#learner = FactorizedDualSpaceModel(SimpleMargin(C=1024, kernel='rbf'), partition=PARTITION, mode='positive', sample_unknown_proba=0.5)  # Dual Space model\n",
    "#learner = SubspatialVersionSpace(warmup=100, thin=10, n_samples=8, rounding=True, kernel='rbf', gamma=None, partition=PARTITION, label_function='AND', loss='GREEDY')\n",
    "#learner = SubspatialSimpleMargin(C=1024, kernel='rbf', gamma=5, partition=PARTITION, label_function='AND')\n",
    "\n",
    "\n",
    "# RUN EXPLORATION\n",
    "metrics = explore.run(X, labeled_set, learner, repeat=REPEAT, seeds=SEED)  # 'repeat' specifies how many times to repeat the exploration process\n",
    "\n",
    "# COMPUTE AVERAGE F-SCORE OVER ALL REPEATS AND PLOT\n",
    "#plot_fscore(metrics)\n",
    "df = pd.DataFrame.from_dict({i: metric for i, metric in enumerate(metrics[0])}, orient='index')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running multiple experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'warmup': 100,\n",
    "    'thin': 100,\n",
    "    'n_samples': 16,\n",
    "    'jitter': 1e-12,\n",
    "}\n",
    "\n",
    "learners = {\n",
    "    'strategy=default cache=False':              KernelQueryByCommittee(strategy='default', rounding_cache=False, **params), \n",
    "    'strategy=default cache=True':               KernelQueryByCommittee(strategy='default', rounding_cache=True,  **params), \n",
    "    #'strategy=opt cache=False z_cut=False':      KernelQueryByCommittee(strategy='opt',     rounding_cache=False, z_cut=False, **params), \n",
    "    'strategy=opt cache=False z_cut=True':       KernelQueryByCommittee(strategy='opt',     rounding_cache=False, z_cut=True,  **params), \n",
    "    #'strategy=opt cache=True  z_cut=False':       KernelQueryByCommittee(strategy='opt',     rounding_cache=True,  z_cut=False, **params), \n",
    "    'strategy=opt cache=True z_cut=True':        KernelQueryByCommittee(strategy='opt',     rounding_cache=True,  z_cut=True,  **params),\n",
    "}\n",
    "\n",
    "dfs = {}\n",
    "for label, learner in learners.items():\n",
    "    try:\n",
    "        print('start:', label)\n",
    "        metrics = explore.run(X, labeled_set, learner, repeat=REPEAT, seeds=SEED)\n",
    "        dfs[label] = pd.DataFrame.from_dict({i: metric for i, metric in enumerate(metrics[0])}, orient='index')\n",
    "    except:\n",
    "        print('Error at task: {}'.format(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 'fscore' # fscore, iter_time\n",
    "\n",
    "labels = {\n",
    "    'strategy=default cache=False': 'Lovasz',\n",
    "    'strategy=opt cache=False z_cut=True': 'Optimized',\n",
    "    'strategy=default cache=True':  'Lovasz + Caching',\n",
    "    'strategy=opt cache=True  z_cut=True': 'Optimized + Caching'\n",
    "}\n",
    "\n",
    "\n",
    "mask = ~dfs['strategy=default cache=False'][m].isnull()\n",
    "idx = dfs['strategy=default cache=False'].index[mask]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for label, l in labels.items():\n",
    "    df = dfs[label]\n",
    "    plt.plot(idx, df[m].loc[mask], label=l)\n",
    "\n",
    "plt.ylim([0, 1.25])\n",
    "plt.xlim([-1, 103])\n",
    "plt.ylabel('Time per iteration (s)')\n",
    "plt.xlabel('Iteration')\n",
    "plt.legend(loc='upper left', frameon=False)\n",
    "#plt.savefig('/Users/luciano/Downloads/ellipsoid_opt_fscore.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 'iter_time' # fscore, iter_time\n",
    "\n",
    "mask = ~dfs['strategy=default cache=False'][m].isnull()\n",
    "idx = dfs['strategy=default cache=False'].index[mask]\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "for label, df in dfs.items():\n",
    "    plt.plot(idx, df[m].loc[mask], label=label)\n",
    "\n",
    "plt.ylim([0, 1.1])\n",
    "plt.ylabel(m)\n",
    "plt.xlabel('Iteration')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
