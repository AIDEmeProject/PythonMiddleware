{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import usual libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# our system imports\n",
    "from aideme import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fscore(metrics):\n",
    "    df_list = [pd.DataFrame.from_dict({i: metric for i, metric in enumerate(ls)}, orient='index') for ls in metrics]\n",
    "    avg = sum([df['fscore'][~df['fscore'].isna()] for df in df_list]) / len(df_list)\n",
    "    avg.plot(ylim=[0,1], marker='o')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DUMMY DATA\n",
    "N = int(1e5)\n",
    "dim = 2\n",
    "limit = 2 * (0.001)**(1. / dim)\n",
    "rng = np.random.RandomState(0)\n",
    "X = rng.uniform(low=-2, high=2, size=(N, dim))  # do not forget to standardize the data. For this distribution, it should be fine without it.\n",
    "y_subspace = np.vstack([np.abs(X[:, i]) < limit for i in range(dim)]).T.astype('float')  # partial labels (for each subspace)\n",
    "y = y_subspace.min(axis=1)\n",
    "\n",
    "labeled_set = LabeledSet(y, y_subspace)\n",
    "\n",
    "# visualize data distribution\n",
    "print('selectivity :', 100 * y.sum() / len(y), '%')\n",
    "\n",
    "#plt.figure(figsize=(10,8))\n",
    "#plt.scatter(X[:, 0], X[:, 1], s=0.5, c=['b' if lb else 'r' for lb in y])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET-UP EXPLORATION CONFIGURATION\n",
    "REPEAT = 1\n",
    "NUMBER_OF_ITERATIONS = 80  # number of points to be labeled by the user\n",
    "\n",
    "SUBSAMPLING = None  # \n",
    "\n",
    "INITIAL_SAMPLER = stratified_sampler(labeled_set, pos=1, neg=1)  # start with one random positive sample and one random negative sample\n",
    "#INITIAL_SAMPLER = random_sampler(10)\n",
    "\n",
    "CALLBACK = [ # callback functions to be called at the end of each iteration\n",
    "    classification_metrics(labeled_set.labels, ['fscore']), \n",
    "    three_set_metric,\n",
    "]\n",
    "CALLBACK_SKIP = 10\n",
    "PRINT_CALLBACK_RESULT = True\n",
    "\n",
    "CONVERGENCE_CRITERIA = [\n",
    "    max_iter_reached(NUMBER_OF_ITERATIONS),\n",
    "    #all_points_are_known,\n",
    "    #metric_reached_threshold('fscore', 0.8),\n",
    "    metric_reached_threshold('tsm', 0.9),\n",
    "]\n",
    "\n",
    "#NOISE_INJECTOR = random_noise_injector(0)  # None, random_noise_injector, gaussian_noise_injector\n",
    "\n",
    "SEED = list(range(REPEAT))\n",
    "\n",
    "explore = PoolBasedExploration(INITIAL_SAMPLER, SUBSAMPLING, CALLBACK, CALLBACK_SKIP, PRINT_CALLBACK_RESULT, CONVERGENCE_CRITERIA)\n",
    "\n",
    "# ACTIVE LEARNING ALGORITHMS\n",
    "#learner = RandomSampler(SVC(C=1e5, kernel='rbf', gamma='auto'))  # choose a random point\n",
    "#learner = SimpleMargin(C=1e7, kernel='rbf')  # choose point closest to SVM decision boundary\n",
    "#learner = DualSpaceModel(learner, sample_unknown_proba=0.5, mode='positive')  # Dual Space model\n",
    "learner = KernelQueryByCommittee(n_samples=8, warmup=100, thin=100, rounding=True, rounding_cache=True, z_cut=True, strategy='opt')  # version space algorithm\n",
    "\n",
    "# FACTORIZED ALGORITHMS\n",
    "PARTITION = [[0], [1]]\n",
    "#learner = FactorizedDualSpaceModel(SimpleMargin(C=1024, kernel='rbf'), partition=PARTITION, mode='positive', sample_unknown_proba=0.5)  # Dual Space model\n",
    "#learner = SubspatialVersionSpace(warmup=100, thin=10, n_samples=8, rounding=True, kernel='rbf', gamma=None, partition=PARTITION, label_function='AND', loss='GREEDY')\n",
    "#learner = SubspatialSimpleMargin(C=1024, kernel='rbf', gamma=5, partition=PARTITION, label_function='AND')\n",
    "\n",
    "\n",
    "# RUN EXPLORATION\n",
    "metrics = explore.run(X, labeled_set, learner, repeat=REPEAT, seeds=SEED)  # 'repeat' specifies how many times to repeat the exploration process\n",
    "\n",
    "# COMPUTE AVERAGE F-SCORE OVER ALL REPEATS AND PLOT\n",
    "#plot_fscore(metrics)\n",
    "df = pd.DataFrame.from_dict({i: metric for i, metric in enumerate(metrics[0])}, orient='index')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
